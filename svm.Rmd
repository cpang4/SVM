---
title: "Support Vector Machines"
output: html_document
---

```{r, echo=T, eval=T, warnings=F, message=F} 
# load packages
library(e1071)
library(knitr)
```

## Iris Dataset
```{r, echo=F, eval=T, warnings=F} 
# load data
iris <- iris
head(iris)
```

```{r, echo=T, eval=T, warnings=F} 
# Pairwise Plot
cols <- character(nrow(iris))
cols[] <- "black"
cols[iris$Species == "setosa"] <- "slateblue"
cols[iris$Species == "versicolor"] <- "grey25"
cols[iris$Species == "virginica"] <- "tomato2"
pairs(iris[,1:4], col = cols)
```

```{r, echo=T, eval=T, warnings=F} 
# partition X matrix and y response
X <- iris[,1:4]
y <- as.factor(iris$Species) # as factor

# sample with seed and partition training and test sets
set.seed(1) # set seed
trn.idx <- sample(1:nrow(iris), round(nrow(iris)*0.8, 0))
tst.idx <- (-trn.idx)
train <- iris[c(trn.idx),]
test <- iris[c(-trn.idx),]

X.trn <- X[c(trn.idx),]
y.trn <- y[trn.idx]
X.tst <- X[c(tst.idx),]
y.tst <- y[tst.idx]
```

#### Build SVM model with linear kernel
```{r, echo=T, eval=T, warnings=F} 
svm.linear.out <- svm(Species ~., data = train, kernel = "linear")
svm.linear.out
head(svm.linear.out$SV) # display support vectors used for classification

# evaluate performance 
pred.train <- predict(svm.linear.out, X.trn) # training response
mean(pred.train == y.trn) # prediction accuracy
table(pred.train, y.trn) # confusion matrix

pred.test <- predict(svm.linear.out, X.tst) # test response
mean(pred.test == y.tst) 
table(pred.test, y.tst)
```

#### Build SVM model with polynomial kernel
```{r, echo=T, eval=T, warnings=F} 
svm.poly.out <- svm(Species ~., data = train, kernel = "polynomial")
svm.poly.out
head(svm.poly.out$SV) # display support vectors used for classification

# evaluate performance 
pred.train <- predict(svm.poly.out, X.trn) # training response
mean(pred.train == y.trn) # prediction accuracy
table(pred.train, y.trn) # confusion matrix

pred.test <- predict(svm.poly.out, X.tst) # test response
mean(pred.test == y.tst) 
table(pred.test, y.tst)
```
   
Tuning parameters: kernel type, classification type, C (regularization term), gamma   
Larger values of C are more precise, but may overfit on training data, while smaller values of C are less precise and have a larger error rate.  
Larger gamma considers points closest to determine margin, and inversely, smaller gammas consider points further away from "center" to determine margin.  
    
```{r, echo=T, eval=T, warnings=F} 
# Declare vectors for tuning
kernels <- c("linear", "polynomial", "radial", "sigmoid")
types <- c("C-classification", "nu-classification")
gam.vect <- c(0.01, 0.1, 0.25, 0.5, 1, 5, 10)
c.vect <- c(0.01, 0.1, 0.5, 1, 2, 5)
```

#### Grid-search to find optimal model
```{r, echo=T, eval=T, warnings=F} 
svm.df <- as.character(data.frame())
for (i in 1:length(kernels)) {
  for (j in 1:length(types)) {
    # tune svm
    set.seed(1)
    svm.out <- tune.svm(Species ~., data = train, gamma = gam.vect, cost = c.vect, kernel = kernels[i], type = types[j])
    best.params <- svm.out$best.parameters # best parameters from grid search
    set.seed(1)
    svm.best.mod <- svm(Species ~., data = train, gamma = best.params$gamma, cost = best.params$cost, kernel = kernels[i], type = types[j])
    
    pred.train <- predict(svm.best.mod, X.trn) # training response
    trn.acc <- mean(pred.train == y.trn) 
    # table(pred.train, y.trn)
    pred.test <- predict(svm.best.mod, X.tst) # test response
    tst.acc <- mean(pred.test == y.tst)
    # table(pred.test, y.tst)
    
    temp.vect <- c(kernels[i], types[j], best.params$gamma, best.params$cost, round(trn.acc,3), round(tst.acc,3), sum(svm.best.mod$nSV))
    svm.df <- rbind(svm.df, as.character(temp.vect))
  }
}
colnames(svm.df) <- c("kernel", "type", "best.gamma", "best.c", "training.acc", "test.acc", "num.sp.vects") # modify column names
```

```{r, echo=F, eval=T, warnings=F} 
kable(svm.df, caption = "Iris Grid-Search Results", align = c("c", "r"))
```

      
## Wisconsin Breast Cancer Dataset
```{r, echo=F, eval=T, warnings=F} 
# load data
options(width = 120)
bc <- read.csv(file = "MA 373 STAT MODELING/DATA/wisconsin breast cancer.csv", header = T)
head(bc)
```


```{r, echo=T, eval=T, warnings=F} 
# clean data
bc <- bc[,-1] # get rid of id column
bc[,1] <- as.factor(bc[,1])
X <- bc[,c(2:ncol(bc))]
y <- bc[,1]
colnames(bc)[1] <- "type"

# pairwise plot iris data
cols <- character(nrow(bc))
cols[] <- "slateblue"
cols[bc$type == "M"] <- "tomato2"
dev.new()
pairs(bc[,2:10], col = cols) # first 9 columns
```


```{r, echo=T, eval=T, warnings=F} 
# Example of overlapping points
plot(bc$X0.2776, bc$X0.07871, col = cols) # overlapping data plot
```


```{r, echo=T, eval=T, warnings=F} 
# sample with seed and partition training and test sets
set.seed(1) # set seed
trn.idx <- sample(1:nrow(bc), round(nrow(bc)*0.8, 0))
tst.idx <- (-trn.idx)
train <- bc[c(trn.idx),]
test <- bc[c(-trn.idx),]

X.trn <- X[c(trn.idx),]
y.trn <- y[trn.idx]
X.tst <- X[c(tst.idx),]
y.tst <- y[tst.idx]
```

#### Perform grid-search to tune method
```{r, echo=T, eval=T, warnings=F} 
# get data frame of grid search results
svm.df <- as.character(data.frame())
for (i in 1:length(kernels)) {
  for (j in 1:length(types)) {
    # tune svm
    set.seed(1)
    svm.out <- tune.svm(type ~., data = train, gamma = gam.vect, cost = c.vect, kernel = kernels[i], type = types[j])
    best.params <- svm.out$best.parameters # best parameters from grid search
    set.seed(1)
    svm.best.mod <- svm(type ~., data = train, gamma = best.params$gamma, cost = best.params$cost, kernel = kernels[i], type = types[j])
    
    pred.train <- predict(svm.best.mod, X.trn) # training response
    trn.acc <- mean(pred.train == y.trn) 
    # table(pred.train, y.trn)
    pred.test <- predict(svm.best.mod, X.tst) # test response
    tst.acc <- mean(pred.test == y.tst)
    # table(pred.test, y.tst)
    
    temp.vect <- c(kernels[i], types[j], best.params$gamma, best.params$cost, round(trn.acc,3), round(tst.acc,3), sum(svm.best.mod$nSV))
    svm.df <- rbind(svm.df, as.character(temp.vect))
  }
}
colnames(svm.df) <- c("kernel", "type", "best.gamma", "best.c", "training.acc", "test.acc", "num.sp.vects") # modify column names
```


```{r, echo=F, eval=T, warnings=F} 
kable(svm.df, caption = "Breast Cancer Grid-Search Results", align = c("c", "r"))
```


